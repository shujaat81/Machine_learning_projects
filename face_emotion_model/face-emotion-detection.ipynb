{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/example_submission.csv\n",
      "/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013/fer2013/README\n",
      "/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013/fer2013/fer2013.csv\n",
      "/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013/fer2013/fer2013.bib\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load and Read dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013/fer2013/fer2013.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take a look on the dataset we have**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training       28709\n",
       "PrivateTest     3589\n",
       "PublicTest      3589\n",
       "Name: Usage, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Usage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pull out dataset in different categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data['Usage']== 'Training'].copy()\n",
    "data_val = data[data['Usage']=='PublicTest'].copy()\n",
    "data_test = data[data['Usage']=='PrivateTest'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28709, 3), \n",
      "validation shape: (3589, 3), \n",
      "test shape: (3589, 3)\n"
     ]
    }
   ],
   "source": [
    "print('train shape: {}, \\nvalidation shape: {}, \\ntest shape: {}'.format(data_train.shape,data_val.shape,data_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Parameters\n",
    "num_classes = 7\n",
    "epochs = 55\n",
    "batch_size = 64\n",
    "num_features = 32\n",
    "width, height = 48,48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform CRNO (CRNO stands for Convert,Reshape, Normalize, one-hot-encoding)\n",
    "def CRNO(df,dataName):\n",
    "    df['pixels'] = df['pixels'].apply(lambda pixel_sequence: [int(pixel) for pixel in pixel_sequence.split()])\n",
    "    data_X = np.array(df['pixels'].tolist(),dtype='float32').reshape(-1,width,height,1)/255.0\n",
    "    data_Y = to_categorical(df['emotion'],num_classes)\n",
    "    print(dataName, \"_X shape: {}, \", dataName, \"_Y shape: {}\".format(data_X.shape, data_Y.shape))\n",
    "    return data_X,data_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train _X shape: {},  train _Y shape: (28709, 48, 48, 1)\n",
      "validation _X shape: {},  validation _Y shape: (3589, 48, 48, 1)\n",
      "test _X shape: {},  test _Y shape: (3589, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X,train_Y = CRNO(data_train,'train')\n",
    "val_X,val_Y = CRNO(data_val,'validation')\n",
    "test_X,test_Y = CRNO(data_test,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import important libraries for model creation and training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries before model creation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,BatchNormalization\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building Model and compiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       33024     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 256)         65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 673,095\n",
      "Trainable params: 671,687\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Build the model\n",
    "model = Sequential()\n",
    "#Module1 conv<<conv<<batchnorm<<relu<<maxpooling<<dropout\n",
    "model.add(Conv2D(2*num_features,kernel_size=(3,3),padding='same',data_format='channels_last',input_shape=(width, height, 1)))\n",
    "model.add(Conv2D(2*num_features,kernel_size=(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(rate=0.2))\n",
    "#Module2 conv<<conv<<batchnorm<<relu<<maxpool<<dropout\n",
    "model.add(Conv2D(2*2*num_features,kernel_size=(3,3),padding='same'))\n",
    "model.add(Conv2D(2*2*num_features,kernel_size=(3,3),padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(rate=0.2))\n",
    "#Module3 conv<<conv<<batchnorm<<relu<<maxpool<<dropout\n",
    "model.add(Conv2D(2*2*2*num_features,kernel_size=(1,1),padding='same'))\n",
    "model.add(Conv2D(2*2*2*num_features,kernel_size=(1,1),strides=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(rate=0.2))\n",
    "#Module4 fc<<batchnorm<<fc<<batchnorm<<dropout<<softmax\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999),metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/50\n",
      " - 17s - loss: 1.8307 - accuracy: 0.2985 - val_loss: 1.9389 - val_accuracy: 0.2917\n",
      "Epoch 2/50\n",
      " - 13s - loss: 1.5073 - accuracy: 0.4225 - val_loss: 1.5038 - val_accuracy: 0.4079\n",
      "Epoch 3/50\n",
      " - 13s - loss: 1.3808 - accuracy: 0.4733 - val_loss: 1.6477 - val_accuracy: 0.4129\n",
      "Epoch 4/50\n",
      " - 13s - loss: 1.3205 - accuracy: 0.5029 - val_loss: 1.6864 - val_accuracy: 0.3410\n",
      "Epoch 5/50\n",
      " - 13s - loss: 1.2813 - accuracy: 0.5172 - val_loss: 1.4464 - val_accuracy: 0.4514\n",
      "Epoch 6/50\n",
      " - 13s - loss: 1.2461 - accuracy: 0.5263 - val_loss: 1.3841 - val_accuracy: 0.4767\n",
      "Epoch 7/50\n",
      " - 13s - loss: 1.2261 - accuracy: 0.5363 - val_loss: 1.3289 - val_accuracy: 0.5015\n",
      "Epoch 8/50\n",
      " - 13s - loss: 1.2056 - accuracy: 0.5469 - val_loss: 1.2783 - val_accuracy: 0.5015\n",
      "Epoch 9/50\n",
      " - 13s - loss: 1.1879 - accuracy: 0.5533 - val_loss: 1.2114 - val_accuracy: 0.5442\n",
      "Epoch 10/50\n",
      " - 13s - loss: 1.1692 - accuracy: 0.5608 - val_loss: 1.3454 - val_accuracy: 0.4946\n",
      "Epoch 11/50\n",
      " - 13s - loss: 1.1487 - accuracy: 0.5681 - val_loss: 1.3046 - val_accuracy: 0.5085\n",
      "Epoch 12/50\n",
      " - 13s - loss: 1.1405 - accuracy: 0.5731 - val_loss: 1.2909 - val_accuracy: 0.5026\n",
      "Epoch 13/50\n",
      " - 13s - loss: 1.1240 - accuracy: 0.5787 - val_loss: 1.1910 - val_accuracy: 0.5545\n",
      "Epoch 14/50\n",
      " - 13s - loss: 1.1116 - accuracy: 0.5819 - val_loss: 1.1535 - val_accuracy: 0.5581\n",
      "Epoch 15/50\n",
      " - 13s - loss: 1.1018 - accuracy: 0.5840 - val_loss: 1.6014 - val_accuracy: 0.3904\n",
      "Epoch 16/50\n",
      " - 13s - loss: 1.0899 - accuracy: 0.5907 - val_loss: 1.1531 - val_accuracy: 0.5645\n",
      "Epoch 17/50\n",
      " - 13s - loss: 1.0673 - accuracy: 0.6008 - val_loss: 1.1620 - val_accuracy: 0.5626\n",
      "Epoch 18/50\n",
      " - 13s - loss: 1.0593 - accuracy: 0.6073 - val_loss: 1.2887 - val_accuracy: 0.5244\n",
      "Epoch 19/50\n",
      " - 13s - loss: 1.0495 - accuracy: 0.6086 - val_loss: 1.1747 - val_accuracy: 0.5573\n",
      "Epoch 20/50\n",
      " - 13s - loss: 1.0431 - accuracy: 0.6084 - val_loss: 1.2042 - val_accuracy: 0.5461\n",
      "Epoch 21/50\n",
      " - 13s - loss: 1.0281 - accuracy: 0.6158 - val_loss: 1.1647 - val_accuracy: 0.5720\n",
      "Epoch 22/50\n",
      " - 13s - loss: 1.0213 - accuracy: 0.6167 - val_loss: 1.2001 - val_accuracy: 0.5506\n",
      "Epoch 23/50\n",
      " - 13s - loss: 1.0050 - accuracy: 0.6230 - val_loss: 1.1834 - val_accuracy: 0.5564\n",
      "Epoch 24/50\n",
      " - 13s - loss: 1.0029 - accuracy: 0.6242 - val_loss: 1.1476 - val_accuracy: 0.5681\n",
      "Epoch 25/50\n",
      " - 13s - loss: 0.9871 - accuracy: 0.6309 - val_loss: 1.1951 - val_accuracy: 0.5495\n",
      "Epoch 26/50\n",
      " - 13s - loss: 0.9815 - accuracy: 0.6329 - val_loss: 1.2360 - val_accuracy: 0.5492\n",
      "Epoch 27/50\n",
      " - 13s - loss: 0.9740 - accuracy: 0.6353 - val_loss: 1.1643 - val_accuracy: 0.5673\n",
      "Epoch 28/50\n",
      " - 13s - loss: 0.9596 - accuracy: 0.6392 - val_loss: 1.1902 - val_accuracy: 0.5528\n",
      "Epoch 29/50\n",
      " - 13s - loss: 0.9542 - accuracy: 0.6399 - val_loss: 1.1555 - val_accuracy: 0.5698\n",
      "Epoch 30/50\n",
      " - 13s - loss: 0.9429 - accuracy: 0.6498 - val_loss: 1.1369 - val_accuracy: 0.5734\n",
      "Epoch 31/50\n",
      " - 13s - loss: 0.9416 - accuracy: 0.6487 - val_loss: 1.1765 - val_accuracy: 0.5609\n",
      "Epoch 32/50\n",
      " - 13s - loss: 0.9415 - accuracy: 0.6488 - val_loss: 1.1356 - val_accuracy: 0.5787\n",
      "Epoch 33/50\n",
      " - 13s - loss: 0.9200 - accuracy: 0.6569 - val_loss: 1.1590 - val_accuracy: 0.5773\n",
      "Epoch 34/50\n",
      " - 13s - loss: 0.9218 - accuracy: 0.6547 - val_loss: 1.1696 - val_accuracy: 0.5709\n",
      "Epoch 35/50\n",
      " - 13s - loss: 0.9123 - accuracy: 0.6584 - val_loss: 1.2038 - val_accuracy: 0.5578\n",
      "Epoch 36/50\n",
      " - 13s - loss: 0.9076 - accuracy: 0.6609 - val_loss: 1.2483 - val_accuracy: 0.5475\n",
      "Epoch 37/50\n",
      " - 13s - loss: 0.8983 - accuracy: 0.6636 - val_loss: 1.1288 - val_accuracy: 0.5915\n",
      "Epoch 38/50\n",
      " - 13s - loss: 0.8923 - accuracy: 0.6685 - val_loss: 1.1300 - val_accuracy: 0.5918\n",
      "Epoch 39/50\n",
      " - 13s - loss: 0.8795 - accuracy: 0.6712 - val_loss: 1.1327 - val_accuracy: 0.5815\n",
      "Epoch 40/50\n",
      " - 13s - loss: 0.8793 - accuracy: 0.6765 - val_loss: 1.1569 - val_accuracy: 0.5756\n",
      "Epoch 41/50\n",
      " - 13s - loss: 0.8770 - accuracy: 0.6733 - val_loss: 1.1924 - val_accuracy: 0.5614\n",
      "Epoch 42/50\n",
      " - 13s - loss: 0.8717 - accuracy: 0.6737 - val_loss: 1.1960 - val_accuracy: 0.5642\n",
      "Epoch 43/50\n",
      " - 13s - loss: 0.8682 - accuracy: 0.6796 - val_loss: 1.1921 - val_accuracy: 0.5648\n",
      "Epoch 44/50\n",
      " - 13s - loss: 0.8586 - accuracy: 0.6790 - val_loss: 1.1448 - val_accuracy: 0.5762\n",
      "Epoch 45/50\n",
      " - 13s - loss: 0.8480 - accuracy: 0.6833 - val_loss: 1.1552 - val_accuracy: 0.5807\n",
      "Epoch 46/50\n",
      " - 13s - loss: 0.8436 - accuracy: 0.6854 - val_loss: 1.1305 - val_accuracy: 0.5876\n",
      "Epoch 47/50\n",
      " - 13s - loss: 0.8413 - accuracy: 0.6861 - val_loss: 1.1474 - val_accuracy: 0.5834\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience = 10, mode = 'min', restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_X,train_Y,batch_size=batch_size,epochs=50,verbose=2,callbacks=[es],validation_split=0,validation_data=(val_X,val_Y),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Test Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Model Accuracy on test set: 0.5896\n"
     ]
    }
   ],
   "source": [
    "test_true = np.argmax(test_Y, axis=1)\n",
    "test_pred = np.argmax(model.predict(test_X), axis=1)\n",
    "print(\"CNN Model Accuracy on test set: {:.4f}\".format(accuracy_score(test_true, test_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
